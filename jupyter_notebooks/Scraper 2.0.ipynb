{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraper of Google and Apple Mobility reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook loads Google and Apple Mobility reports, builds cleaned reports in different formats and builds merged files from both sources.\n",
    "\n",
    "Original data:\n",
    "    - Google Community Mobility reports: https://www.google.com/covid19/mobility/\n",
    "    - Apple Mobility Trends reports: https://www.apple.com/covid19/mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_google_reports(\n",
    "        directory_pdf=os.path.join(\n",
    "            \"google_reports\",\n",
    "            \"pdf_reports\"),\n",
    "        directory_csv=\"google_reports\"):\n",
    "    '''Download Google Community Mobility reports in CSV and PDF format\n",
    "\n",
    "        Args:\n",
    "            directory_pdf: directory to which PDF reports will be downloaded\n",
    "            directory_csv: directory to which CSV report will be downloaded\n",
    "\n",
    "        Returns:\n",
    "            new_files (bool): flag indicating whether or not new files have been downloaded\n",
    "    '''\n",
    "    # get webpage source\n",
    "    url = 'https://www.google.com/covid19/mobility/'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    new_files = False\n",
    "\n",
    "    # create directories if they don't exist\n",
    "    if not os.path.exists(directory_pdf):\n",
    "        os.makedirs(directory_pdf)\n",
    "    if not os.path.exists(directory_csv):\n",
    "        os.makedirs(directory_csv)\n",
    "\n",
    "    # download CSV file\n",
    "    csv_tag = soup.find('a', {\"class\": \"icon-link\"})\n",
    "    link = csv_tag['href']\n",
    "    file_name = \"Global_Mobility_Report.csv\"\n",
    "    path = os.path.join(directory_csv, file_name)\n",
    "    if not os.path.isfile(path):\n",
    "        new_files = True\n",
    "        urllib.request.urlretrieve(link, path)\n",
    "        print(file_name)\n",
    "        time.sleep(1)\n",
    "    else:\n",
    "        path_new = os.path.join(directory_csv, file_name + \"_new\")\n",
    "        urllib.request.urlretrieve(link, path_new)\n",
    "        if os.path.getsize(path) == os.path.getsize(path_new):\n",
    "            os.remove(path_new)\n",
    "        else:\n",
    "            new_files = True\n",
    "            os.remove(path)\n",
    "            os.rename(path_new, path)\n",
    "    # download PDFs\n",
    "    json_data = re.search(\n",
    "        r\"window.templateData=JSON.parse\\('([^']+)\", response.text)\n",
    "    json_data = bytes(json_data.groups()[0], 'utf-8').decode('unicode_escape')\n",
    "    json_data = json.loads(json_data)\n",
    "\n",
    "    def get_pdf_files(e):\n",
    "        link = e['pdfLink']\n",
    "        file_name = link[link.find('mobility') + len('mobility') + 1:]\n",
    "        if link[-3:] == \"pdf\":\n",
    "            path = os.path.join(directory_pdf, file_name)\n",
    "            if not os.path.isfile(path):\n",
    "                new_files = True\n",
    "                urllib.request.urlretrieve(link, path)\n",
    "                print(file_name)\n",
    "                time.sleep(1)\n",
    "\n",
    "    for elem in json_data['countries']:\n",
    "        get_pdf_files(elem)\n",
    "        for child in elem['childRegions']:\n",
    "            get_pdf_files(child)\n",
    "\n",
    "    if not new_files:\n",
    "        print('Google: No updates')\n",
    "    return new_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_google_report(\n",
    "        source=\"Global_Mobility_Report.csv\",\n",
    "        destination=\"mobility_report.csv\",\n",
    "        report_type=\"regions\"):\n",
    "    '''Build cleaned Google report for worldwide or for some country (currently only for the US)\n",
    "\n",
    "        Args:\n",
    "            source: location of the raw Google CSV report\n",
    "            destination: destination file path\n",
    "            report_type: two options available: \"regions\" - report for worldwide, \"US\" - report for the US\n",
    "    '''\n",
    "    df = pd.read_csv(source, low_memory=False)\n",
    "    df = df.drop(columns=['country_region_code'])\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            'country_region': 'country',\n",
    "            'retail_and_recreation_percent_change_from_baseline': 'retail',\n",
    "            'grocery_and_pharmacy_percent_change_from_baseline': 'grocery and pharmacy',\n",
    "            'parks_percent_change_from_baseline': 'parks',\n",
    "            'transit_stations_percent_change_from_baseline': 'transit stations',\n",
    "            'workplaces_percent_change_from_baseline': 'workplaces',\n",
    "            'residential_percent_change_from_baseline': 'residential'})\n",
    "    if report_type == \"regions\":\n",
    "        df = df[df['sub_region_2'].isnull()]\n",
    "        df = df.drop(columns=['sub_region_2'])\n",
    "        df = df.rename(columns={'sub_region_1': 'region'})\n",
    "        df['region'].fillna('Total', inplace=True)\n",
    "    elif report_type == \"US\":\n",
    "        df = df[(df['country'] == \"United States\")]\n",
    "        df = df.drop(columns=['country'])\n",
    "        df = df.rename(\n",
    "            columns={\n",
    "                'sub_region_1': 'state',\n",
    "                'sub_region_2': 'county'})\n",
    "        df['state'].fillna('Total', inplace=True)\n",
    "        df['county'].fillna('Total', inplace=True)\n",
    "    df.to_csv(destination, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: Apple can unexpectedly change version\n",
    "def download_apple_report(directory=\"apple_reports\"):\n",
    "    '''Download Apple Mobility Trends report in CSV\n",
    "\n",
    "        Args:\n",
    "            directory: directory to which CSV report will be downloaded\n",
    "\n",
    "        Returns:\n",
    "            new_files (bool): flag indicating whether or not a new file has been downloaded\n",
    "    '''\n",
    "    version = \"v2\"\n",
    "    json_link = \"https://covid19-static.cdn-apple.com/covid19-mobility-data/current/\" + version + \"/index.json\"\n",
    "    with urllib.request.urlopen(json_link) as url:\n",
    "           json_data = json.loads(url.read().decode())\n",
    "    link = \"https://covid19-static.cdn-apple.com\" + json_data['basePath'] + json_data['regions']['en-us']['csvPath']\n",
    "    new_files = False\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    file_name = \"applemobilitytrends.csv\"\n",
    "    if link[-3:] == \"csv\":\n",
    "        path = os.path.join(directory, file_name)\n",
    "        if not os.path.isfile(path):\n",
    "            new_files = True\n",
    "            urllib.request.urlretrieve(link, path)\n",
    "            print(file_name)\n",
    "        else:\n",
    "            path_new = os.path.join(directory, file_name + \"_new\")\n",
    "            urllib.request.urlretrieve(link, path_new)\n",
    "            if os.path.getsize(path) == os.path.getsize(path_new):\n",
    "                os.remove(path_new)\n",
    "            else:\n",
    "                new_files = True\n",
    "                os.remove(path)\n",
    "                os.rename(path_new, path)\n",
    "\n",
    "    if not new_files:\n",
    "        print('Apple: No updates')\n",
    "    return new_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_apple_report(\n",
    "    source=os.path.join(\n",
    "        'apple_reports',\n",
    "        \"applemobilitytrends.csv\"),\n",
    "        destination=os.path.join(\n",
    "            'apple_reports',\n",
    "        \"apple_mobility_report.csv\")):\n",
    "    '''Build cleaned Apple report (transform dates from columns to rows, add country names for subregions and cities)\n",
    "\n",
    "        Args:\n",
    "            source: location of the raw Apple CSV report\n",
    "            destination: destination file path\n",
    "    '''\n",
    "    apple = pd.read_csv(source)\n",
    "    apple = apple.drop(columns=['alternative_name'])\n",
    "    subcity_country_file = os.path.join(\n",
    "        'auxiliary_data', 'sub&city_country_Apple.csv')\n",
    "\n",
    "    if os.path.isfile(subcity_country_file):\n",
    "        subcity_country = pd.read_csv(subcity_country_file, index_col=0)\n",
    "    else:\n",
    "        subcity_country = None\n",
    "\n",
    "    apple['country'] = apple.apply(lambda x: subcity_country.loc[x['region'], 'country'] if (\n",
    "        x['geo_type'] != 'country/region' and subcity_country is not None and x['region'] in subcity_country.index) else x['region'], axis=1)\n",
    "    apple = apple.melt(\n",
    "        id_vars=[\n",
    "            'geo_type',\n",
    "            'region',\n",
    "            'transportation_type',\n",
    "            'country'],\n",
    "        var_name='date')\n",
    "    apple['value'] = apple['value'] - 100\n",
    "    apple = apple.pivot_table(\n",
    "        index=[\n",
    "            \"geo_type\",\n",
    "            \"region\",\n",
    "            \"date\",\n",
    "            \"country\"],\n",
    "        columns='transportation_type').reset_index()\n",
    "    apple.columns = [t + (v if v != \"value\" else \"\") for v, t in apple.columns]\n",
    "    apple['subregion_and_city'] = apple.apply(lambda x: x['region'] if (\n",
    "        x['geo_type'] != 'country/region') else \"Total\", axis=1)\n",
    "    apple = apple[['country', 'subregion_and_city',\n",
    "                   'geo_type', 'date', 'driving', 'transit', 'walking']]\n",
    "    apple = apple.sort_values(by=['country', 'subregion_and_city', 'date'])\n",
    "    apple.to_csv(destination, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_summary_report(\n",
    "    apple_source=os.path.join(\n",
    "        'apple_reports',\n",
    "        \"applemobilitytrends.csv\"),\n",
    "        google_source=os.path.join(\n",
    "            \"google_reports\",\n",
    "            \"Global_Mobility_Report.csv\"),\n",
    "    destination=os.path.join(\n",
    "        \"summary_reports\",\n",
    "        \"summary_report.csv\")):\n",
    "    '''Build a merged report from Google and Apple data\n",
    "\n",
    "        Args:\n",
    "            apple_source: location of the raw Apple CSV report\n",
    "            google_source: location of the raw Google CSV report\n",
    "            destination: destination file path\n",
    "    '''\n",
    "    # preprocess apple data\n",
    "    apple = pd.read_csv(apple_source)\n",
    "    apple = apple.drop(columns=['alternative_name'])\n",
    "    subcity_country_file = os.path.join(\n",
    "        'auxiliary_data', 'sub&city_country_Apple.csv')\n",
    "\n",
    "    if os.path.isfile(subcity_country_file):\n",
    "        subcity_country = pd.read_csv(subcity_country_file, index_col=0)\n",
    "    else:\n",
    "        subcity_country = None\n",
    "\n",
    "    apple['country'] = apple.apply(lambda x: subcity_country.loc[x['region'], 'country'] if (\n",
    "        x['geo_type'] != 'country/region' and subcity_country is not None and x['region'] in subcity_country.index) else x['region'], axis=1)\n",
    "    apple = apple.melt(\n",
    "        id_vars=[\n",
    "            'geo_type',\n",
    "            'region',\n",
    "            'transportation_type',\n",
    "            'country'],\n",
    "        var_name='date')\n",
    "    apple['value'] = apple['value'] - 100\n",
    "    apple = apple.pivot_table(\n",
    "        index=[\n",
    "            \"geo_type\",\n",
    "            \"region\",\n",
    "            \"date\",\n",
    "            \"country\"],\n",
    "        columns='transportation_type').reset_index()\n",
    "    apple.columns = [t + (v if v != \"value\" else \"\") for v, t in apple.columns]\n",
    "    apple['sub_region_1'] = apple.apply(lambda x: x['region'] if (\n",
    "        x['geo_type'] != 'country/region') else \"Total\", axis=1)\n",
    "    apple = apple[['country', 'sub_region_1',\n",
    "                   'date', 'driving', 'transit', 'walking']]\n",
    "\n",
    "    country_AtoG_file = os.path.join(\n",
    "        'auxiliary_data', 'country_Apple_to_Google.csv')\n",
    "    subregions_AtoG_file = os.path.join(\n",
    "        'auxiliary_data', 'subregions_Apple_to_Google.csv')\n",
    "\n",
    "    if os.path.isfile(country_AtoG_file):\n",
    "        country_AtoG = pd.read_csv(country_AtoG_file, index_col=0)\n",
    "    else:\n",
    "        country_AtoG = None\n",
    "    if os.path.isfile(subregions_AtoG_file):\n",
    "        subregions_AtoG = pd.read_csv(subregions_AtoG_file, index_col=0)\n",
    "    else:\n",
    "        subregions_AtoG = None\n",
    "        \n",
    "    apple['country'] = apple.apply(lambda x: country_AtoG.loc[x['country'], 'country_google'] if (\n",
    "        country_AtoG is not None and x['country'] in country_AtoG.index) else x['country'], axis=1)\n",
    "    apple['sub_region_1'] = apple.apply(lambda x: subregions_AtoG.loc[x['sub_region_1'], 'subregion_Google'] if (\n",
    "        subregions_AtoG is not None and x['sub_region_1'] in subregions_AtoG.index) else x['sub_region_1'], axis=1)   \n",
    "\n",
    "    apple['sub_region_2'] = \"Total\"\n",
    "\n",
    "    # process google data\n",
    "    google = pd.read_csv(google_source, low_memory=False)\n",
    "    google['sub_region_1'].fillna('Total', inplace=True)\n",
    "    google['sub_region_2'].fillna('Total', inplace=True)\n",
    "    google = google.rename(\n",
    "        columns={\n",
    "            'country_region': 'country',\n",
    "            'retail_and_recreation_percent_change_from_baseline': 'retail',\n",
    "            'grocery_and_pharmacy_percent_change_from_baseline': 'grocery and pharmacy',\n",
    "            'parks_percent_change_from_baseline': 'parks',\n",
    "            'transit_stations_percent_change_from_baseline': 'transit stations',\n",
    "            'workplaces_percent_change_from_baseline': 'workplaces',\n",
    "            'residential_percent_change_from_baseline': 'residential'})\n",
    "    summary = pd.merge(\n",
    "        google, apple, how='outer', left_on=[\n",
    "            'country', 'sub_region_1', 'sub_region_2', 'date'], right_on=[\n",
    "            'country', 'sub_region_1', 'sub_region_2', 'date'], sort=True)\n",
    "    summary = summary.drop(\n",
    "        columns=['country_region_code'])\n",
    "    summary['sub_region_2'].fillna('Total', inplace=True)\n",
    "    summary = summary.sort_values(\n",
    "        by=['country', 'sub_region_1', 'sub_region_2', 'date'])\n",
    "    summary.to_csv(destination, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_summary_report(\n",
    "    source=os.path.join(\n",
    "        \"summary_reports\",\n",
    "        \"summary_report.csv\"),\n",
    "        destination_regions=os.path.join(\n",
    "            \"summary_reports\",\n",
    "            \"summary_report_regions.csv\"),\n",
    "    destination_countries=os.path.join(\n",
    "        \"summary_reports\",\n",
    "        \"summary_report_countries.csv\"),\n",
    "    destination_US=os.path.join(\n",
    "        \"summary_reports\",\n",
    "        \"summary_report_US.csv\")):\n",
    "    '''Slice a merged report into 3 next subreports:\n",
    "        1) Summary report by regions without US counties\n",
    "        2) Summary report by countries\n",
    "        3) Summary report for the US only\n",
    "\n",
    "        Args:\n",
    "            source: location of the summary CSV report\n",
    "            destination_regions: destination for report #1\n",
    "            destination_countries: destination for report #2\n",
    "            destination_US: destination for report #3\n",
    "    '''\n",
    "    # read full summary report\n",
    "    summary = pd.read_csv(source, low_memory=False)\n",
    "    # create report #1\n",
    "    regions = summary[summary['sub_region_2'] == 'Total']\n",
    "    regions = regions.drop(columns=['sub_region_2'])\n",
    "    regions.to_csv(destination_regions, index=False)\n",
    "    # create report #2\n",
    "    countries = summary[summary['sub_region_1'] == 'Total']\n",
    "    countries = countries.drop(columns=['sub_region_1', 'sub_region_2'])\n",
    "    countries.to_csv(destination_countries, index=False)\n",
    "    # create report #3\n",
    "    US = summary[summary['country'] == 'United States']\n",
    "    US.to_csv(destination_US, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_excel(csv_path, excel_path):\n",
    "    \"\"\"Helper function which create Excel file from CSV\"\"\"\n",
    "    df = pd.read_csv(csv_path, low_memory=False)\n",
    "    df.to_excel(excel_path, index=False, sheet_name='Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process Google reports\n",
    "new_files_status_google = download_google_reports()\n",
    "if new_files_status_google:\n",
    "    build_google_report(\n",
    "        source=os.path.join(\n",
    "            \"google_reports\",\n",
    "            \"Global_Mobility_Report.csv\"),\n",
    "        destination=os.path.join(\n",
    "            \"google_reports\",\n",
    "            \"mobility_report_countries.csv\"),\n",
    "        report_type=\"regions\")\n",
    "    build_google_report(\n",
    "        source=os.path.join(\n",
    "            \"google_reports\",\n",
    "            \"Global_Mobility_Report.csv\"),\n",
    "        destination=os.path.join(\n",
    "            \"google_reports\",\n",
    "            \"mobility_report_US.csv\"),\n",
    "        report_type=\"US\")\n",
    "    csv_to_excel(\n",
    "        os.path.join(\n",
    "            \"google_reports\",\n",
    "            \"mobility_report_countries.csv\"),\n",
    "        os.path.join(\n",
    "            \"google_reports\",\n",
    "            \"mobility_report_countries.xlsx\"))\n",
    "    csv_to_excel(os.path.join(\"google_reports\", \"mobility_report_US.csv\"),\n",
    "                 os.path.join(\"google_reports\", \"mobility_report_US.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process Apple reports\n",
    "new_files_status_apple = download_apple_report()\n",
    "if new_files_status_apple:\n",
    "    build_apple_report()\n",
    "    csv_to_excel(\n",
    "        os.path.join(\n",
    "            'apple_reports',\n",
    "            \"apple_mobility_report.csv\"),\n",
    "        os.path.join(\n",
    "            'apple_reports',\n",
    "            \"apple_mobility_report.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build summary report\n",
    "if new_files_status_apple or new_files_status_google:\n",
    "    build_summary_report()\n",
    "    csv_to_excel(\n",
    "        os.path.join(\n",
    "            \"summary_reports\",\n",
    "            \"summary_report.csv\"),\n",
    "        os.path.join(\n",
    "            \"summary_reports\",\n",
    "            \"summary_report.xlsx\"))\n",
    "    # slice summary report\n",
    "    slice_summary_report()\n",
    "    csv_to_excel(\n",
    "        os.path.join(\n",
    "            \"summary_reports\",\n",
    "            \"summary_report_regions.csv\"),\n",
    "        os.path.join(\n",
    "            \"summary_reports\",\n",
    "            \"summary_report_regions.xlsx\"))\n",
    "    csv_to_excel(\n",
    "        os.path.join(\n",
    "            \"summary_reports\",\n",
    "            \"summary_report_countries.csv\"),\n",
    "        os.path.join(\n",
    "            \"summary_reports\",\n",
    "            \"summary_report_countries.xlsx\"))\n",
    "    csv_to_excel(\n",
    "        os.path.join(\n",
    "            \"summary_reports\",\n",
    "            \"summary_report_US.csv\"),\n",
    "        os.path.join(\n",
    "            \"summary_reports\",\n",
    "            \"summary_report_US.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
